{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webtoon Recommendation System\n",
    "***by Chung-Ang Univ. COCAUIN_Team***\n",
    "\n",
    "Our team presents **Webtoon Recommendation System**(based on NAVER Webtoon Service) based on **three different models** .\n",
    "\n",
    "## **1. Latent factor based Collaborative Filtering**  \n",
    "## **2. Item based Collaborative Filtering**  \n",
    "## **3. 'Surprise' based recommendation system**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP_COUNT:  0 RMSE : 3.532614660716394\n",
      "STEP_COUNT:  40 RMSE : 0.4428637719198905\n",
      "STEP_COUNT:  80 RMSE : 0.3302075532662343\n",
      "STEP_COUNT:  120 RMSE : 0.2968993703202772\n",
      "STEP_COUNT:  160 RMSE : 0.28072334925892345\n",
      "í‰ì  ë§¤ê¸´ ì˜í™”ìˆ˜: 14 ì¶”ì²œëŒ€ìƒ ì˜í™”ìˆ˜: 135 ì „ì²´ ì˜í™”ìˆ˜: 149\n",
      "\n",
      " %%%% í™©ì˜ˆì€ %%%% ë‹˜ì˜ \n",
      "\n",
      "## ì¶”ì²œ 5ê°œ ì›¹íˆ° ##  \n",
      "                         pred_score\n",
      "ë„¤ì´ë²„ ìˆ˜ìš”ì¼ ì›¹íˆ° [ê³ ì‚¼ë¬´ìŒ]         5.522287\n",
      "ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [ì‹ ê³¼ í•¨ê»˜]         5.394038\n",
      "ë„¤ì´ë²„ ì¼ìš”ì¼ ì›¹íˆ° [ë§ˆë£¨í•œ-êµ¬í˜„ë™í™”ì „]    5.093802\n",
      "ë„¤ì´ë²„ í† ìš”ì¼ ì›¹íˆ° [íšŒì¶˜]           5.069422\n",
      "ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [ì—¬ì¤‘ìƒ A]         5.045176\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# (1) Latent factor based Collaborative Filtering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):   # R = rating_matrix\n",
    "    error = 0\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "def matrix_factorization(R, K , steps = 200, learning_rate = 0.01, r_lambda = 0.01):\n",
    "    num_users, num_items = R.shape\n",
    "    np.random.seed(1)\n",
    "    P = np.random.normal(scale = 1./K, size = (num_users, K))\n",
    "    Q = np.random.normal(scale = 1./K, size = (num_items, K))\n",
    "    \n",
    "    prev_rmse = 10000\n",
    "    break_count = 0\n",
    "    \n",
    "    non_zeros = [(i,j,R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j]>0]\n",
    "    \n",
    "    for step in range(steps):\n",
    "        for i, j, r in non_zeros:\n",
    "            eij = r - np.dot(P[i,:], Q[j, :].T)\n",
    "            P[i,:] = P[i,:] + learning_rate*(eij * Q[j,:] - r_lambda*P[i,:])\n",
    "            Q[j,:] = Q[j,:] + learning_rate*(eij * P[i,:] - r_lambda*Q[j,:])\n",
    "            \n",
    "        rmse = get_rmse(R,P,Q, non_zeros)\n",
    "        if (step%40) == 0:\n",
    "            print('STEP_COUNT: ', step, 'RMSE :', rmse)\n",
    "            \n",
    "    return P, Q\n",
    "\n",
    "def get_unseen_webtoons(rating_matrix, userId):\n",
    "    user_rating = rating_matrix.loc[userId,:]\n",
    "    already_seen = user_rating[ user_rating > 0].index.tolist()\n",
    "    webtoons_list = rating_matrix.columns.tolist()\n",
    "    unseen_list = [ webtoon for webtoon in webtoons_list if webtoon not in already_seen]\n",
    "    print('í‰ì  ë§¤ê¸´ ì˜í™”ìˆ˜:',len(already_seen), 'ì¶”ì²œëŒ€ìƒ ì˜í™”ìˆ˜:',len(unseen_list), \\\n",
    "          'ì „ì²´ ì˜í™”ìˆ˜:',len(webtoons_list))\n",
    "    \n",
    "    return unseen_list\n",
    "\n",
    "def recomm_webtoons_by_userid(rating_matrix, pred_array, userId, unseen_list, top_n=5):\n",
    "    \n",
    "    pred_df=pd.DataFrame(data=pred_array, columns=rating_matrix.columns, index=rating_matrix.index)\n",
    "    recomm_webtoons = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
    "    recomm_webtoons_df = pd.DataFrame(data=recomm_webtoons.values,index=recomm_webtoons.index,columns=['pred_score'])\n",
    "    \n",
    "    return recomm_webtoons_df\n",
    "\n",
    "\n",
    "# load data\n",
    "survey = pd.read_csv('webtoons_survey(preprocessed).csv')\n",
    "survey.replace('ì—†ìŒ', np.NaN, inplace=True)\n",
    "survey=survey.astype('float64')\n",
    "\n",
    "P, Q = matrix_factorization(survey.values, K=30, steps=200, learning_rate=0.01, r_lambda = 0.01)\n",
    "pred_matrix = np.dot(P, Q.T)\n",
    "\n",
    "\n",
    "# show recommendation list\n",
    "find_user = pd.read_csv('webtoons_survey(original_form).csv')\n",
    "\n",
    "users= ['í™©ì˜ˆì€']  # input name of users as lists\n",
    "\n",
    "for user in users:\n",
    "    userid=int(find_user[find_user['ì´ë¦„']==user].index[0])\n",
    "    unseen_list = get_unseen_webtoons(survey, userid)\n",
    "    recomm_webtoons=recomm_webtoons_by_userid(survey, pred_matrix, userid, unseen_list, top_n=5)\n",
    "    \n",
    "    print('\\n', '%%%% {} %%%% ë‹˜ì˜'.format(user), '\\n')\n",
    "    print('## ì¶”ì²œ 5ê°œ ì›¹íˆ° ## ', '\\n', recomm_webtoons)\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>íƒ€ì„ìŠ¤íƒ¬í”„</th>\n",
       "      <th>ê·€í•˜ì˜ ì„±ë³„ì€?</th>\n",
       "      <th>í˜„ì¬ê¹Œì§€ ê°ìƒí•œ ì›¹íˆ° ì‘í’ˆì„ ì ìˆ˜(1~5ì )ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”ğŸ˜ƒ ë³´ì§€ ì•Šìœ¼ì‹  ì‘í’ˆì€ \"ì—†ìŒ\"ì— í‘œì‹œí•´ì£¼ì„¸ìš”.</th>\n",
       "      <th>ë„¤ì´ë²„ ì›”ìš”ì¼ ì›¹íˆ° [ì‹ ì˜ íƒ‘]</th>\n",
       "      <th>ë„¤ì´ë²„ ì›”ìš”ì¼ ì›¹íˆ° [ë·°í‹°í’€ êµ°ë°”ë¦¬]</th>\n",
       "      <th>ë„¤ì´ë²„ í™”ìš”ì¼ ì›¹íˆ° [ì—¬ì‹ ê°•ë¦¼]</th>\n",
       "      <th>ë„¤ì´ë²„ í™”ìš”ì¼ ì›¹íˆ° [ë§ˆìŒì˜ ì†Œë¦¬]</th>\n",
       "      <th>ë„¤ì´ë²„ ìˆ˜ìš”ì¼ ì›¹íˆ° [ìœ ë¯¸ì˜ ì„¸í¬ë“¤]</th>\n",
       "      <th>ë„¤ì´ë²„ ìˆ˜ìš”ì¼ ì›¹íˆ° [í—¬í¼2 : í‚¬ë² ë¡œìŠ¤]</th>\n",
       "      <th>ë„¤ì´ë²„ ê¸ˆìš”ì¼ ì›¹íˆ° [ì™¸ëª¨ì§€ìƒì£¼ì˜]</th>\n",
       "      <th>ë„¤ì´ë²„ ê¸ˆìš”ì¼ ì›¹íˆ° [ìŠ¤ìœ„íŠ¸í™ˆ]</th>\n",
       "      <th>ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [í›„ë ˆìì‹]</th>\n",
       "      <th>ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [í•œë²ˆ ë” í•´ìš”]</th>\n",
       "      <th>ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [ë…¸ë¸”ë ˆìŠ¤]</th>\n",
       "      <th>ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [ëŒ€í•™ì¼ê¸°]</th>\n",
       "      <th>ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [ì¹˜ì¦ˆì¸ë”íŠ¸ë©]</th>\n",
       "      <th>ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [íŒ¨ì…˜ì™•]</th>\n",
       "      <th>ì´ë¦„</th>\n",
       "      <th>ì—°ë½ì²˜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2020. 1. 4 ì˜¤í›„ 12:27:43</td>\n",
       "      <td>ì—¬</td>\n",
       "      <td>ì˜ˆ, ì½ê³  í™•ì¸í–ˆìŠµë‹ˆë‹¤.</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>í™©ì˜ˆì€</td>\n",
       "      <td>01096558430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    íƒ€ì„ìŠ¤íƒ¬í”„ ê·€í•˜ì˜ ì„±ë³„ì€?  \\\n",
       "8  2020. 1. 4 ì˜¤í›„ 12:27:43        ì—¬   \n",
       "\n",
       "  í˜„ì¬ê¹Œì§€ ê°ìƒí•œ ì›¹íˆ° ì‘í’ˆì„ ì ìˆ˜(1~5ì )ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”ğŸ˜ƒ ë³´ì§€ ì•Šìœ¼ì‹  ì‘í’ˆì€ \"ì—†ìŒ\"ì— í‘œì‹œí•´ì£¼ì„¸ìš”.   \\\n",
       "8                                      ì˜ˆ, ì½ê³  í™•ì¸í–ˆìŠµë‹ˆë‹¤.           \n",
       "\n",
       "  ë„¤ì´ë²„ ì›”ìš”ì¼ ì›¹íˆ° [ì‹ ì˜ íƒ‘] ë„¤ì´ë²„ ì›”ìš”ì¼ ì›¹íˆ° [ë·°í‹°í’€ êµ°ë°”ë¦¬] ë„¤ì´ë²„ í™”ìš”ì¼ ì›¹íˆ° [ì—¬ì‹ ê°•ë¦¼]  \\\n",
       "8                 5                    3                 2   \n",
       "\n",
       "  ë„¤ì´ë²„ í™”ìš”ì¼ ì›¹íˆ° [ë§ˆìŒì˜ ì†Œë¦¬] ë„¤ì´ë²„ ìˆ˜ìš”ì¼ ì›¹íˆ° [ìœ ë¯¸ì˜ ì„¸í¬ë“¤] ë„¤ì´ë²„ ìˆ˜ìš”ì¼ ì›¹íˆ° [í—¬í¼2 : í‚¬ë² ë¡œìŠ¤]  \\\n",
       "8                   4                    4                       5   \n",
       "\n",
       "  ë„¤ì´ë²„ ê¸ˆìš”ì¼ ì›¹íˆ° [ì™¸ëª¨ì§€ìƒì£¼ì˜] ë„¤ì´ë²„ ê¸ˆìš”ì¼ ì›¹íˆ° [ìŠ¤ìœ„íŠ¸í™ˆ] ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [í›„ë ˆìì‹] ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [í•œë²ˆ ë” í•´ìš”]  \\\n",
       "8                   3                 5                4                   4   \n",
       "\n",
       "  ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [ë…¸ë¸”ë ˆìŠ¤] ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [ëŒ€í•™ì¼ê¸°] ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [ì¹˜ì¦ˆì¸ë”íŠ¸ë©] ë„¤ì´ë²„ ì™„ê²° ì›¹íˆ° [íŒ¨ì…˜ì™•]   ì´ë¦„  \\\n",
       "8                5                5                  5               4  í™©ì˜ˆì€   \n",
       "\n",
       "           ì—°ë½ì²˜  \n",
       "8  01096558430  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "find_user = pd.read_csv('webtoons_survey(original_form).csv')\n",
    "find_user = find_user.replace('ì—†ìŒ', np.NaN)\n",
    "find_user[(find_user['ì´ë¦„']=='í™©ì˜ˆì€')].dropna(how='any',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Item based Collaborative Filtering\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_rmse_Item(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    \n",
    "    return np.sqrt(mean_squared_error(pred, actual))\n",
    "\n",
    "def get_item_sim_df(ratings_matrix):\n",
    "    \n",
    "    ratings_matrix_T = ratings_matrix.transpose()\n",
    "    item_sim = cosine_similarity(ratings_matrix_T, ratings_matrix_T)\n",
    "    item_sim_df = pd.DataFrame(data=item_sim, index=ratings_matrix.columns,\n",
    "                          columns=ratings_matrix.columns)\n",
    "    return item_sim_df\n",
    "\n",
    "def predict_rating_topsim(ratings_arr, item_sim_arr, n=10):\n",
    "    \n",
    "    pred = np.zeros(ratings_arr.shape)\n",
    "\n",
    "    for col in range(ratings_arr.shape[1]):\n",
    "        top_n_items = [np.argsort(item_sim_arr[:, col])[:-n-1:-1]]\n",
    "        for row in range(ratings_arr.shape[0]):\n",
    "            pred[row, col] = item_sim_arr[col, :][top_n_items].dot(ratings_arr[row, :][top_n_items].T) \n",
    "            pred[row, col] /= np.sum(np.abs(item_sim_arr[col, :][top_n_items]))        \n",
    "    \n",
    "    return pred\n",
    "\n",
    "def get_ratings_pred_matrix(ratings_matrix, top_n):\n",
    "    \n",
    "    ratings_pred_arr = predict_rating_topsim(ratings_matrix.values, get_item_sim_df(ratings_matrix).values, n=top_n)\n",
    "    \n",
    "    return ratings_pred_arr\n",
    "\n",
    "def get_preferred_top_n(ratings_matrix, userId, top_n):\n",
    "    \n",
    "    user_rating_id = ratings_matrix.loc[userId, :]\n",
    "    \n",
    "    return user_rating_id[ user_rating_id > 0].sort_values(ascending=False)[:top_n]\n",
    "\n",
    "def get_unseen_webtoons(ratings_matrix, userId):\n",
    "\n",
    "    user_rating = ratings_matrix.loc[userId,:]\n",
    "    already_seen = user_rating[ user_rating > 0].index.tolist()\n",
    "    \n",
    "    webtoons_list = ratings_matrix.columns.tolist()\n",
    "    unseen_list = [ webtoon for webtoon in webtoons_list if webtoon not in already_seen]\n",
    "    \n",
    "    return unseen_list\n",
    "\n",
    "def recomm_webtoons_by_userid(rating_matrix, pred_array, userId, unseen_list, top_n=5):\n",
    "    \n",
    "    pred_df=pd.DataFrame(data=pred_array, columns=rating_matrix.columns, index=rating_matrix.index)\n",
    "    recomm_webtoons = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
    "    recomm_webtoons_df = pd.DataFrame(data=recomm_webtoons.values,index=recomm_webtoons.index,columns=['pred_score'])\n",
    "    \n",
    "    return recomm_webtoons_df\n",
    "\n",
    "def show_result_Item(rating_matrix, userId):\n",
    "    \n",
    "    ratings_pred_arr=get_ratings_pred_matrix(rating_matrix, 10)\n",
    "    preferred_webtoons=get_preferred_top_n(rating_matrix, 235, 5)\n",
    "    unseen_list = get_unseen_webtoons(rating_matrix, userId)\n",
    "    recomm_webtoons = recomm_webtoons_by_userid(survey, ratings_pred_arr, userId, unseen_list, top_n=5)\n",
    "    \n",
    "    return preferred_webtoons, recomm_webtoons\n",
    "\n",
    "# load data\n",
    "survey = pd.read_csv('webtoons_survey(preprocessed).csv')\n",
    "survey.replace('ì—†ìŒ', np.NaN, inplace=True)\n",
    "survey = survey.astype('float64')\n",
    "survey = survey.fillna(0)\n",
    "\n",
    "\n",
    "# show recommendation list\n",
    "find_user = pd.read_csv('webtoons_survey(original_form).csv')\n",
    "\n",
    "users= [???]  # input name of users as lists\n",
    "\n",
    "for user in users:\n",
    "    userid=int(find_user[find_user['ì´ë¦„']==user].index[0])\n",
    "    result=show_result_Item(survey, userid)\n",
    "    \n",
    "    print('\\n', '%%%% {} %%%% ë‹˜ì˜'.format(user), '\\n')\n",
    "#     print('## ì„ í˜¸ 5ê°œ ì›¹íˆ° ## ', '\\n', result[0], '\\n')\n",
    "    print('## ì¶”ì²œ 5ê°œ ì›¹íˆ° ## ', '\\n', result[1])\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) 'Surprise' based recommendation system\n",
    "\n",
    "import surprise\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "def get_unseen_surprise(ratings, webtoons, userId):\n",
    "    \n",
    "    seen_webtoons = ratings[ratings['userId']== userId]['webtoonId'].tolist()\n",
    "    \n",
    "    total_webtoons = webtoons.columns[:-1].tolist()\n",
    "    \n",
    "    unseen_webtoons= [webtoon for webtoon in total_webtoons if webtoon not in seen_webtoons]\n",
    "    print('í‰ì  ë§¤ê¸´ ì˜í™”ìˆ˜:',len(seen_webtoons), 'ì¶”ì²œëŒ€ìƒ ì˜í™”ìˆ˜:',len(unseen_webtoons), \\\n",
    "          'ì „ì²´ ì˜í™”ìˆ˜:',len(total_webtoons))\n",
    "    \n",
    "    return unseen_webtoons\n",
    "\n",
    "def recomm_webtoon_by_surprise(algo, userId, unseen_webtoons, top_n=10):\n",
    "    predictions=[algo.predict(str(userId), str(webtoonId)) for webtoonId in unseen_webtoons]\n",
    "    \n",
    "    def sortkey_est(pred):\n",
    "        return pred.est\n",
    "    \n",
    "    predictions.sort(key=sortkey_est, reverse=True)\n",
    "    top_predictions=predictions[:top_n]\n",
    "    \n",
    "    top_webtoon_titles=[pred.iid for pred in top_predictions]\n",
    "    top_webtoon_rating = [pred.est for pred in top_predictions]\n",
    "    \n",
    "    top_webtoon_preds= [(title, rating) for title, rating in zip(top_webtoon_titles, top_webtoon_rating)]\n",
    "    \n",
    "    return top_webtoon_preds\n",
    "\n",
    "# load data and model fitting\n",
    "webtoons = pd.read_csv('webtoons_survey(preprocessed).csv')\n",
    "ratings=pd.read_csv('webtoons_survey(surprise).csv')\n",
    "ratings=ratings.dropna(subset=['rating'])\n",
    "\n",
    "reader = Reader(rating_scale=(1.0, 5.0))\n",
    "\n",
    "data_folds = DatasetAutoFolds(df=ratings, reader=reader)\n",
    "trainset = data_folds.build_full_trainset()\n",
    "\n",
    "algo = SVD(n_epochs=200, n_factors=30, random_state=0)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# show recommendation list\n",
    "find_user = pd.read_csv('webtoons_survey(original_form).csv')\n",
    "\n",
    "users= [???]  # input name of users as lists\n",
    "\n",
    "print('##### Surprise ëª¨ë¸ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ #####')\n",
    "for user in users:\n",
    "    userid=int(find_user[find_user['ì´ë¦„']==user].index[0])\n",
    "    unseen_webtoons = get_unseen_surprise(ratings, webtoons, userid)\n",
    "    top_webtoon_preds=recomm_webtoon_by_surprise(algo, userid, unseen_webtoons, top_n=5)\n",
    "\n",
    "    print('\\n', '%%%% {} %%%% ë‹˜ì˜'.format(user), '\\n')\n",
    "    print('## ì¶”ì²œ 5ê°œ ì›¹íˆ° ## ', '\\n')\n",
    "    for top_webtoon in top_webtoon_preds:\n",
    "        print(top_webtoon[0], ':', top_webtoon[1])\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0388  1.0433  0.9849  1.0258  1.0771  1.0340  0.0298  \n",
      "MAE (testset)     0.8265  0.8192  0.7825  0.8173  0.8551  0.8201  0.0232  \n",
      "Fit time          0.40    0.39    0.38    0.38    0.38    0.39    0.01    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.03882731, 1.04325884, 0.98488007, 1.02577387, 1.07712922]),\n",
       " 'test_mae': array([0.82649253, 0.819209  , 0.782535  , 0.81727934, 0.85506067]),\n",
       " 'fit_time': (0.4041006565093994,\n",
       "  0.3929879665374756,\n",
       "  0.3849978446960449,\n",
       "  0.3809778690338135,\n",
       "  0.3762342929840088),\n",
       " 'test_time': (0.011968135833740234,\n",
       "  0.01096653938293457,\n",
       "  0.01194310188293457,\n",
       "  0.011946916580200195,\n",
       "  0.011963367462158203)}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(algo, data_folds, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0419455403024\n",
      "{'n_epochs': 40, 'n_factors': 20}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [40, 80, 120, 200], 'n_factors': [10, 20, 30, 50, 100] }\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data_folds)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
